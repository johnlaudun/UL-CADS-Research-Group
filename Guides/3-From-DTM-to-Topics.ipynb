{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 1-8 Comparing Texts Redux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd#, numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Set plt parameters\n",
    "# plt.rcParams['figure.dpi'] = 300\n",
    "# plt.rcParams[\"figure.figsize\"] = (10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 \"Off there to the right -- somewhere -- is a large\n"
     ]
    }
   ],
   "source": [
    "# This is a very creaky way to load data\n",
    "files = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"mdg\"]\n",
    "\n",
    "strings = []\n",
    "for i in files:\n",
    "    # Create the path to the file\n",
    "    the_file = \"../data/1924/texts/\"+i+\".txt\"\n",
    "    # Read the file to a string\n",
    "    the_string =  open(the_file, 'r').read()\n",
    "    # Add the string to a list of strings\n",
    "    strings.append(the_string)\n",
    "\n",
    "print(len(strings), strings[8][0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous lab, you calculated the term frequency for a document, and then for a set of documents. Term frequency is defined as the **relative frequency** of term t within document d. \n",
    "\n",
    "It's useful to explore within a single document and to compare terms across documents, perhaps beginning to establish what a document is about, but what if there was a way to weight TFs such that we lowered the value of terms that occur across a lot, if not all, documents?\n",
    "\n",
    "Enter IDF. Developed in 1972 by Karen Jones, the inverse document frequency (IDF) is a measure of how much information a word provides: if it is common or rare across all documents.\n",
    "\n",
    "It is the logarithmically scaled inverse fraction of the documents that contain the word. IDF is obtained by dividing the total number of documents by the number of documents containing the term, and then taking the logarithm of that quotient. *Phew*.\n",
    "\n",
    "We can weight our term frequencies then by the inverse document frequency to get a better sense of how a word contributes to the distinctiveness of a document (text). The math is simple `tf * idf`. Are you ready to do some math?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2337)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize our texts with just one parameter: \n",
    "# no words that don't occur in at least two texts\n",
    "vectorizer = TfidfVectorizer(lowercase = True,\n",
    "                             min_df = 2,\n",
    "                             stop_words='english')\n",
    "\n",
    "# fit the model to the data \n",
    "tfidf = vectorizer.fit_transform(strings)\n",
    "\n",
    "# We'll need these later\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# see how many features we have\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_that_</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absorbed</th>\n",
       "      <th>abstraction</th>\n",
       "      <th>...</th>\n",
       "      <th>ye</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yelled</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.011566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.011566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031355</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.066189</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.012755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007079</td>\n",
       "      <td>0.025511</td>\n",
       "      <td>0.034975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011090</td>\n",
       "      <td>0.012755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052463</td>\n",
       "      <td>0.077868</td>\n",
       "      <td>0.012755</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.052463</td>\n",
       "      <td>0.040512</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.022181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.028818</td>\n",
       "      <td>0.049386</td>\n",
       "      <td>0.028906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031812</td>\n",
       "      <td>0.077264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>0.014453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019674</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>0.025134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>0.009458</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.009458</td>\n",
       "      <td>0.015746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047288</td>\n",
       "      <td>0.019449</td>\n",
       "      <td>0.015746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.047433</td>\n",
       "      <td>0.019449</td>\n",
       "      <td>0.021456</td>\n",
       "      <td>0.019449</td>\n",
       "      <td>0.008223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022333</td>\n",
       "      <td>0.040848</td>\n",
       "      <td>0.011166</td>\n",
       "      <td>0.103472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdg</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>0.008817</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022109</td>\n",
       "      <td>0.012088</td>\n",
       "      <td>0.016001</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 2337 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         _that_   abandon  abandoning   ability      able    abrupt  abruptly  \\\n",
       "label                                                                           \n",
       "A      0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "B      0.000000  0.000000    0.000000  0.020840  0.011566  0.000000  0.014286   \n",
       "C      0.012755  0.000000    0.000000  0.000000  0.007079  0.025511  0.034975   \n",
       "D      0.000000  0.000000    0.014409  0.000000  0.023989  0.000000  0.009877   \n",
       "E      0.000000  0.000000    0.000000  0.000000  0.017170  0.000000  0.000000   \n",
       "F      0.000000  0.028907    0.000000  0.000000  0.000000  0.000000  0.009908   \n",
       "G      0.009458  0.018915    0.018915  0.009458  0.015746  0.000000  0.000000   \n",
       "H      0.000000  0.000000    0.000000  0.000000  0.009040  0.000000  0.000000   \n",
       "mdg    0.000000  0.000000    0.000000  0.000000  0.004893  0.008817  0.006044   \n",
       "\n",
       "       absolutely  absorbed  abstraction  ...        ye      year     years  \\\n",
       "label                                     ...                                 \n",
       "A        0.000000  0.000000     0.000000  ...  0.000000  0.000000  0.000000   \n",
       "B        0.000000  0.036239     0.000000  ...  0.000000  0.028571  0.011566   \n",
       "C        0.000000  0.011090     0.012755  ...  0.000000  0.052463  0.077868   \n",
       "D        0.000000  0.000000     0.014409  ...  0.000000  0.000000  0.007996   \n",
       "E        0.000000  0.000000     0.000000  ...  0.000000  0.031812  0.077264   \n",
       "F        0.014453  0.000000     0.000000  ...  0.028907  0.000000  0.072191   \n",
       "G        0.009458  0.000000     0.000000  ...  0.047288  0.019449  0.015746   \n",
       "H        0.000000  0.000000     0.000000  ...  0.000000  0.000000  0.000000   \n",
       "mdg      0.000000  0.007666     0.000000  ...  0.000000  0.006044  0.009786   \n",
       "\n",
       "         yelled    yellow       yes      york     young   younger     youth  \n",
       "label                                                                        \n",
       "A      0.000000  0.000000  0.027842  0.000000  0.088160  0.000000  0.000000  \n",
       "B      0.000000  0.000000  0.031355  0.014286  0.066189  0.014286  0.000000  \n",
       "C      0.012755  0.008744  0.012794  0.052463  0.040512  0.008744  0.022181  \n",
       "D      0.028818  0.049386  0.028906  0.000000  0.019613  0.000000  0.000000  \n",
       "E      0.000000  0.000000  0.093098  0.000000  0.007019  0.000000  0.000000  \n",
       "F      0.000000  0.009908  0.000000  0.000000  0.019674  0.009908  0.025134  \n",
       "G      0.000000  0.006483  0.047433  0.019449  0.021456  0.019449  0.008223  \n",
       "H      0.000000  0.022333  0.040848  0.011166  0.103472  0.000000  0.000000  \n",
       "mdg    0.000000  0.000000  0.022109  0.012088  0.016001  0.006044  0.000000  \n",
       "\n",
       "[9 rows x 2337 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to a dataframe\n",
    "df = pd.DataFrame(tfidf.toarray(), \n",
    "                  columns = vectorizer.get_feature_names_out())\n",
    "\n",
    "# Label our rows\n",
    "df[\"label\"] = files\n",
    "df.set_index(\"label\", inplace=True)\n",
    "\n",
    "# See what this looks like:\n",
    "df.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>mdg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_that_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009458</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.028907</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoning</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014409</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009458</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011566</td>\n",
       "      <td>0.007079</td>\n",
       "      <td>0.023989</td>\n",
       "      <td>0.01717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015746</td>\n",
       "      <td>0.00904</td>\n",
       "      <td>0.004893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label         A         B         C         D        E         F         G  \\\n",
       "_that_      0.0  0.000000  0.012755  0.000000  0.00000  0.000000  0.009458   \n",
       "abandon     0.0  0.000000  0.000000  0.000000  0.00000  0.028907  0.018915   \n",
       "abandoning  0.0  0.000000  0.000000  0.014409  0.00000  0.000000  0.018915   \n",
       "ability     0.0  0.020840  0.000000  0.000000  0.00000  0.000000  0.009458   \n",
       "able        0.0  0.011566  0.007079  0.023989  0.01717  0.000000  0.015746   \n",
       "\n",
       "label             H       mdg  \n",
       "_that_      0.00000  0.000000  \n",
       "abandon     0.00000  0.000000  \n",
       "abandoning  0.00000  0.000000  \n",
       "ability     0.00000  0.000000  \n",
       "able        0.00904  0.004893  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = df.transpose()\n",
    "words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment this to see it work, but it's over 2000 lines long!\n",
    "# Also, there are more color maps available. (See: pandas docs.)\n",
    "# words.style.background_gradient(axis=None, cmap='Purples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Words = Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have in our first dataframe above is a document-term matrix (DTM), a matrix in which documents are arranged as rows (observations) and terms appear as features of those rows. \n",
    "\n",
    "What if there was some way to re-imagine this matrix in terms of the vector multiplication that assembled it? That is, could we imagine a vector ***W*** that specified the topics around which documents were assembled and then a vector ***H*** which described the relationships of words to those topics. If we could break the output matrix above into its constituent matrices, we might be able to glean what makes these documents tick.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Please note that the \"guesstimation\" approach used below, while frequently used in the past, is generally frowned upon in the current moment. There are better ways to proceed than guesstimating. They involve however casting a number of other spells first, like <b>k-means</b> that we will explore a little later in this course.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there word clusters in this data set?\n",
    "nmf = NMF(n_components=9, \n",
    "          random_state=1, \n",
    "          max_iter=500, \n",
    "          init='nndsvd').fit(tfidf)\n",
    "nmf_W = nmf.transform(tfidf)\n",
    "nmf_H = nmf.components_\n",
    "nmf_W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"{:d}: \".format(topic_idx)\n",
    "        message += \" \".join([feature_names[i] + ' ' + str(round(topic[i], 2)) + ','\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: man 0.43, bird 0.39, tea 0.29, birds 0.29, bees 0.29, professor 0.29, mr 0.25, said 0.24, mother 0.24, oh 0.24,\n",
      "1: father 0.54, priest 0.31, god 0.22, son 0.16, church 0.14, mouth 0.13, like 0.12, boy 0.12, sin 0.12, eyes 0.12,\n",
      "2: henry 0.78, dance 0.19, said 0.13, bank 0.09, dancing 0.09, feet 0.08, read 0.07, time 0.07, moment 0.07, birthday 0.06,\n",
      "3: roman 0.21, walls 0.19, man 0.18, family 0.18, la 0.18, cat 0.17, stone 0.16, did 0.12, unknown 0.11, altar 0.11,\n",
      "4: general 0.65, said 0.22, island 0.11, animal 0.1, night 0.1, sea 0.09, tree 0.09, trail 0.09, mr 0.08, hunter 0.08,\n",
      "5: cot 0.24, iron 0.16, real 0.15, ship 0.15, great 0.15, man 0.14, said 0.14, hospital 0.13, palms 0.12, nurse 0.11,\n",
      "6: george 0.54, father 0.44, uncle 0.42, said 0.29, boat 0.26, baby 0.19, woman 0.17, road 0.17, water 0.16, camp 0.14,\n",
      "7: mr 0.27, man 0.21, american 0.2, said 0.16, sir 0.15, morrow 0.11, round 0.11, friend 0.11, did 0.11, clear 0.09,\n",
      "8: said 0.19, mr 0.17, golf 0.15, like 0.13, girl 0.13, did 0.12, summer 0.11, club 0.11, eyes 0.11, mouth 0.1,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf, vocabulary, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
