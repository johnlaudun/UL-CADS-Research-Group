# Notes

## Theoretical Backgrounds

One of the first things any study needs to consider is its scope: what is it going to cover? In computer science, scope is the space within which a term, or variable, can be reliably referenced. In project management, scope is the specified features of a product, such that the work that needs to be done is clearly set out, broken into workable pieces, and then done. We can harness both meanings in our study, if only because the boundaries of text analytics, indeed of all analytics in the current moment, are so dynamic. (And by dynamic I mean that whatever consensus we might develop here could shift by the end of our study: that is how fast things are changing.)

One way to imagine scope might be to think about the domains involved and the theories, methods, and tools upon which they tend to rely.

![Overlapping Domains](./media/domains.png)

As you can see, in the illustration text analytics occupies a portion of the middle ground of a series of domains, each of which have rather fuzzy scoping. That fuzziness is due in no small part to developments in hardware that have made two things cheap: computational power and storage. (There can be no large language models without billions of texts stored somewhere and suitable amounts of RAM in which to pour them as they are processed by a staggering amount of computational power. It's hard to imagine the computational power involved, but you might think about it in terms of the difference in computational power between your phone and the computers that put men on the moon. It's that expansion, or explosion, of computing power and storage led to a series of developments, a number of which have centered upon, or at least circled around, getting computers to understand language the way humans actually use it. 

We are using text analytics as a working title for the tools and methods we are going to cover, but if we are going to talk about theory, then we need to be aware of the larger contexts. 

Since we are in an English department, it probably makes the most sense to begin with digital humanities. To begin, there are a couple of guides which are useful to peruse just to get a sense of the digital humanities:

* [Getting Started - Digital Humanities - Research Guides at New York University](https://guides.nyu.edu/digital-humanities/getting-started)
* [The Digital Humanities Literacy Guidebook](https://cmu-lib.github.io/dhlg/)
* [Defining Digital Humanities: A Reader | Guide books | ACM Digital Library](https://dl.acm.org/doi/book/10.5555/2601575)

_A Companion to Digital Humanities_ was first published in 2004, which shows how long people have been working on this and how much of a struggle it has been for the domain to be recognized by the departments in which people work. The book is available [online](https://onlinelibrary.wiley.com/doi/book/10.1002/9780470999875) with chapters downloadable as PDFs. 

If you were to ask me to make suggestions for reading for our study, I would probably suggest:

* Susan Hockey's History of Humanities Computing," which is obviously a bit outdated, but it would give you a sense of origins.
* Greg Crane's "Classics and the Computer" because the Perseus Project really was a Herculean effort and it helped to move things like TEI forward. (Text encoding is a later chapter in the book.)
* Thomas Rommel's "Literary Studies" might be worth a quick read, as would be the chapters on linguistics and on stylistics. 
* John Burrows' "Textual Analysis" might be worth a read as well.