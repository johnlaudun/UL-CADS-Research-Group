{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In case you are wondering what this little bit of \"magic\" does: it essentially tells Jupyter notebooks to embed whatever graphic is created by `matplotlib` into the current page.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Exploring a Text with the NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Table of Contents <a name=\"toc\"></a>\n",
    "\n",
    "**[Loading a File & Understanding What It Is](#file)**  \n",
    "**[Tokenizing](#tokenizing)**  \n",
    "[A Quick Note about Normalization](#norm)  \n",
    "[Using regex to Tokenize](#REtoke)   \n",
    "[Using NLTK Tokenizers](#nltktoken)  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the first two notebooks we learned how to load a file, create a word list out of a text string, and then to count words and visualize those counts. In this notebook we will use the `NLTK` to explore how various words occur or are used within a text. Once you have seen how these commands work, feel free to restart the notebook and upload your own text. In the next notebook, we will look at how to load more than one text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load Text and Create Word List\n",
    "\n",
    "The first thing we are going to do is load the libraries we know we are going to use, load our text file, and create our word list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "file = open('texts/hod.txt', 'r').read()\n",
    "words = re.sub(\"[^a-zA-Z']\",\" \", mdg).lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NLTK `Text`\n",
    "\n",
    "Once we have our text as our, by now normal, list of words, we need to prepare it for use by the `NLTK` as a text. The command to do this is frighteningly straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdg_text = nltk.Text(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concordances\n",
    "\n",
    "Once we have our text as, well, a text -- but, better, because `nltk.Text`? -- we can do some pretty amazing things, like develop in what linguists call a *key word in context (KWiC)* concordance. The code for the concordance is fairly simple and straightforward:\n",
    "\n",
    "```python\n",
    "my_text.concordance(\"word\")\n",
    "```\n",
    "\n",
    "You can type the line just like that, and Jupyter notebook will deliver results:\n",
    "\n",
    "```\n",
    "Displaying 4 of 4 matches:\n",
    " that the cape buffalo is the most dangerous of all big game for a moment the g\n",
    "r the cape buffalo is not the most dangerous big game he sipped his wine here i\n",
    " in the same slow tone i hunt more dangerous game rainsford expressed his surpr\n",
    "reason after a fashion so they are dangerous but where do you get them the gene\n",
    "In [22]:\n",
    "```\n",
    "\n",
    "I am somewhat used to putting anything I want to display inside a print function, which is why you'll see it in the code block below. I have also moved the word I want to enter into a variable so I can type it outside of the line of code. This makes it easier to think about making this code part of a `for` loop when I want to investigate a list of words. (See below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Try any of the following: hunt, hunted, hunter, dark, jungle\n",
    "word = \"game\"\n",
    "print(mdg_text.concordance(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['hunter', 'hunted', 'hunt']\n",
    "for word in word_list:\n",
    "    print(mdg_text.concordance(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispersion Plot\n",
    "\n",
    "We will examine more ways to understand the relationship between individual words and the text as their context in a moment, but while we have our text as an object and we have a cluster of words in front of us, it might be useful to demonstrate the utility of being able to see where words occur in a text using the NLTK's dispersion plot functon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdg_text.dispersion_plot([\"hunter\", \"jungle\", \"dark\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you noticed that what you are doing above is feeding the `dispersion_plot()` function a list of words, you are beginning to get the hang of reading code, which means we can break out list out separately and then simply feed the name of the list to the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [\"hunted\", \"hunter\", \"hunt\"]\n",
    "mdg_text.dispersion_plot(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the functions for examining words within a text have pretty straightforward names. Let's take a look at a number of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myword = \"eyes\"\n",
    "print(mdg_text.similar(myword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_contexts allows you to see where two words are used similarly:\n",
    "mdg_text.common_contexts([\"hounds\", \"hunter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please note that the collocations function uses the NLTK's stopwords list\n",
    "# in the background. I am not yet sure how to feed it a custom stopword list.\n",
    "mdg_text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a pretty straightforward function, but useful if you don't feel\n",
    "# like consulting your usually much larger word frequency list.\n",
    "mdg_text.count(\"dangerous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nltk.pos_tag(mdg_words[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = nltk.pos_tag(mdg_words[0:20])\n",
    "for word, value in mylist:\n",
    "    if value == 'NN':\n",
    "        print(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
