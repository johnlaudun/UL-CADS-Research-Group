{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cc2da70-9f28-4259-9a2e-e486728492b2",
   "metadata": {},
   "source": [
    "## Parsing Nominalized Adjectives using StanfordNLP\n",
    "\n",
    "-Like SpaCy, StanFordNLP is another viable library that thrives with Dependency Parsing and thus could be used to identify whether nominalised adjectives are truly functioning within their nominal and head capacity or not. \n",
    "\n",
    "- Here, to use StanfordNLP, I needed to install the 'Stanza\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0212a174-da65-4cce-902b-629b066edc2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stanza in c:\\users\\amusa\\anaconda3\\lib\\site-packages (1.9.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: emoji in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from stanza) (2.14.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from stanza) (1.24.3)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from stanza) (4.23.4)\n",
      "Requirement already satisfied: requests in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from stanza) (2.31.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from stanza) (3.1)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from stanza) (2.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from stanza) (4.65.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (2023.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from requests->stanza) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from requests->stanza) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from requests->stanza) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from requests->stanza) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from tqdm->stanza) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.3.0->stanza) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\amusa\\anaconda3\\lib\\site-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b6bda4-84c6-4980-a214-85d0f46d3475",
   "metadata": {},
   "source": [
    "## Import Stanza\n",
    "- After Installing 'Stanza'\n",
    "- I had to 'import' it\n",
    "- then download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acde4d23-b114-4ea4-b410-88e086e7816c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69bd36067d64a3bbf932f0d48b4cde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 22:40:02 INFO: Downloaded file to C:\\Users\\amusa\\stanza_resources\\resources.json\n",
      "2024-10-22 22:40:02 INFO: Downloading default packages for language: en (English) ...\n",
      "2024-10-22 22:40:05 INFO: File exists: C:\\Users\\amusa\\stanza_resources\\en\\default.zip\n",
      "2024-10-22 22:40:11 INFO: Finished downloading models and saved to C:\\Users\\amusa\\stanza_resources\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "# Download the English model\n",
    "stanza.download('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd00a6f-c140-4112-a763-375a4f7ba093",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Codes for Parsing\n",
    "\n",
    "- These are the step by step analysis\n",
    "- Step 1: Initialize the Stanza pipeline for English\n",
    "- Step 2: Input sentence\n",
    "- Step 3: Process the sentence\n",
    "- Step 4: Print the dependency parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f116c645-def7-450a-a1c7-37c39b589b26",
   "metadata": {},
   "source": [
    "## I used the same sentence \"\"The poor worship the rich people for the needy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb9d501-0f01-489f-a455-31c5e00ff522",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 22:40:25 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a7d9f7f46e442fa1b3593211082b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 22:40:26 INFO: Downloaded file to C:\\Users\\amusa\\stanza_resources\\resources.json\n",
      "2024-10-22 22:40:28 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-10-22 22:40:28 INFO: Using device: cpu\n",
      "2024-10-22 22:40:28 INFO: Loading: tokenize\n",
      "2024-10-22 22:40:32 INFO: Loading: mwt\n",
      "2024-10-22 22:40:32 INFO: Loading: pos\n",
      "2024-10-22 22:40:33 INFO: Loading: lemma\n",
      "2024-10-22 22:40:33 INFO: Loading: constituency\n",
      "2024-10-22 22:40:33 INFO: Loading: depparse\n",
      "2024-10-22 22:40:34 INFO: Loading: sentiment\n",
      "2024-10-22 22:40:34 INFO: Loading: ner\n",
      "2024-10-22 22:40:36 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token           Lemma      POS      Dependency   Head      \n",
      "============================================================\n",
      "The             the        DET      det          worship   \n",
      "poor            poor       ADJ      amod         worship   \n",
      "worship         worship    NOUN     root         ROOT      \n",
      "the             the        DET      det          people    \n",
      "rich            rich       ADJ      amod         people    \n",
      "people          person     NOUN     appos        worship   \n",
      "for             for        ADP      case         needy     \n",
      "the             the        DET      det          needy     \n",
      "needy           needy      NOUN     nmod         people    \n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "# Initialize the Stanza pipeline for English\n",
    "nlp = stanza.Pipeline('en')\n",
    "\n",
    "# Input sentence\n",
    "sentence = \"The poor worship the rich people for the needy\"\n",
    "\n",
    "# Process the sentence\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Print the dependency parse\n",
    "print(f\"{'Token':<15} {'Lemma':<10} {'POS':<8} {'Dependency':<12} {'Head':<10}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sentence in doc.sentences:\n",
    "    for word in sentence.words:\n",
    "        print(f\"{word.text:<15} {word.lemma:<10} {word.upos:<8} {word.deprel:<12} {sentence.words[word.head-1].text if word.head > 0 else 'ROOT':<10}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72efeb47-57f1-45a9-bb9d-2f5cba1deb5a",
   "metadata": {},
   "source": [
    "## Result\n",
    "- Unlike SpaCy, StanfordNLP performs poorly with identifying Nominalized adjectives \n",
    "- It considers 'poor' as an adjective modifying 'worship'\n",
    "- It considers 'rich' as adjective modifying 'people'\n",
    "- it considers 'needy' as noun modifier to 'people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59df6d36-6287-400c-8333-de99ca191c56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 22:45:33 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69c06bb9b774a768e6d23474457b847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 22:45:35 INFO: Downloaded file to C:\\Users\\amusa\\stanza_resources\\resources.json\n",
      "2024-10-22 22:45:37 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-10-22 22:45:37 INFO: Using device: cpu\n",
      "2024-10-22 22:45:37 INFO: Loading: tokenize\n",
      "2024-10-22 22:45:37 INFO: Loading: mwt\n",
      "2024-10-22 22:45:37 INFO: Loading: pos\n",
      "2024-10-22 22:45:38 INFO: Loading: lemma\n",
      "2024-10-22 22:45:38 INFO: Loading: constituency\n",
      "2024-10-22 22:45:39 INFO: Loading: depparse\n",
      "2024-10-22 22:45:40 INFO: Loading: sentiment\n",
      "2024-10-22 22:45:40 INFO: Loading: ner\n",
      "2024-10-22 22:45:42 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token           Lemma      POS      Dependency   Head      \n",
      "============================================================\n",
      "The             the        DET      det          man       \n",
      "old             old        ADJ      amod         man       \n",
      "man             man        NOUN     root         ROOT      \n",
      "the             the        DET      det          poor      \n",
      "poor            poor       ADJ      nmod:npmod   man       \n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "# Initialize the Stanza pipeline for English\n",
    "nlp = stanza.Pipeline('en')\n",
    "\n",
    "# Input sentence\n",
    "sentence = \"The old man the poor\"\n",
    "\n",
    "# Process the sentence\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Print the dependency parse\n",
    "print(f\"{'Token':<15} {'Lemma':<10} {'POS':<8} {'Dependency':<12} {'Head':<10}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sentence in doc.sentences:\n",
    "    for word in sentence.words:\n",
    "        print(f\"{word.text:<15} {word.lemma:<10} {word.upos:<8} {word.deprel:<12} {sentence.words[word.head-1].text if word.head > 0 else 'ROOT':<10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e518dc2-555d-47a4-8771-8cbf5bbeb9e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 22:50:59 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b71bba3fbce49558b1743e0d7fb8574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 22:51:02 INFO: Downloaded file to C:\\Users\\amusa\\stanza_resources\\resources.json\n",
      "2024-10-22 22:51:05 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-10-22 22:51:05 INFO: Using device: cpu\n",
      "2024-10-22 22:51:05 INFO: Loading: tokenize\n",
      "2024-10-22 22:51:05 INFO: Loading: mwt\n",
      "2024-10-22 22:51:05 INFO: Loading: pos\n",
      "2024-10-22 22:51:06 INFO: Loading: lemma\n",
      "2024-10-22 22:51:06 INFO: Loading: constituency\n",
      "2024-10-22 22:51:07 INFO: Loading: depparse\n",
      "2024-10-22 22:51:08 INFO: Loading: sentiment\n",
      "2024-10-22 22:51:09 INFO: Loading: ner\n",
      "2024-10-22 22:51:11 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token           Lemma      POS      Dependency   Head      \n",
      "============================================================\n",
      "Her             her        PRON     nmod:poss    singing   \n",
      "singing         singing    NOUN     nsubj        loveable  \n",
      "is              be         AUX      cop          loveable  \n",
      "loveable        loveable   ADJ      root         ROOT      \n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "# Initialize the Stanza pipeline for English\n",
    "nlp = stanza.Pipeline('en')\n",
    "\n",
    "# Input sentence\n",
    "sentence = \"Her singing is loveable\"\n",
    "\n",
    "# Process the sentence\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Print the dependency parse\n",
    "print(f\"{'Token':<15} {'Lemma':<10} {'POS':<8} {'Dependency':<12} {'Head':<10}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sentence in doc.sentences:\n",
    "    for word in sentence.words:\n",
    "        print(f\"{word.text:<15} {word.lemma:<10} {word.upos:<8} {word.deprel:<12} {sentence.words[word.head-1].text if word.head > 0 else 'ROOT':<10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d770be86-b842-4dea-89e5-f3333c0d90bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
